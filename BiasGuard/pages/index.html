<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>BiasGuard | Responsible AI Trust Layer</title>
  <style>
    body {
      font-family: "Segoe UI", sans-serif;
      margin: 0;
      background-color: #f9f9fb;
      color: #1a1a1a;
      line-height: 1.6;
    }
    header {
      background: #000;
      padding: 0;
    }
    header img {
      width: 100%;
      display: block;
    }
    .container {
      max-width: 920px;
      margin: auto;
      padding: 2rem;
    }
    h1, h2 {
      color: #1a1a1a;
    }
    .hero-image, .full-width {
      width: 100%;
      margin: 1.5rem 0;
      border-radius: 8px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.08);
    }
    .stakeholders td {
      padding: 0.5rem;
      vertical-align: top;
    }
    footer {
      text-align: center;
      font-size: 0.85rem;
      margin-top: 4rem;
      padding-top: 2rem;
      color: #777;
    }
    a {
      color: #007acc;
      text-decoration: none;
    }
  </style>
</head>
<body>

<header>
  <img src="../assets/biasguard-logo-motto-header.png" alt="BiasGuard Logo" />
</header>

<div class="container">

  <h1>BiasGuard: The Indispensable Trust Layer for Responsible AI</h1>

  <p><strong>BiasGuard</strong> is an open-source policy enforcement framework that makes AI systems accountable, auditable, and aligned with ethical and legal standards from the start.</p>

  <p>Inspired by tools like CloudFormation Guard and OPA, BiasGuard provides rule-based bias prevention, attribution enforcement, and transparency — all embedded directly in your AI/ML workflows.</p>

  <h2>⚠️ Why We Need BiasGuard</h2>
  <ul>
    <li>🧑‍⚖️ A lawyer citing fake cases from ChatGPT</li>
    <li>🌐 Dragnet-style scraping of public content by LLMs</li>
    <li>🤖 Models chaining to other systems without oversight or attribution</li>
  </ul>
  <p>BiasGuard is the policy firewall AI has been missing.</p>
  <img class="hero-image" src="../assets/why-we-need-biasguard.png" alt="Why We Need BiasGuard" />

  <h2>🧠 What Is BiasGuard?</h2>
  <p><em>Explain Like I'm 6:</em> BiasGuard is like a superhero for AI — it helps catch and prevent bias before it causes problems!</p>
  <img class="hero-image" src="../assets/what_is_biasguard.png" alt="What Is BiasGuard?" />

  <h2>🌍 Who Relies on BiasGuard?</h2>
  <table class="stakeholders">
    <tr><td>🔧 <strong>Developers</strong></td><td>Codify fairness, test model behavior, block unsafe outputs</td></tr>
    <tr><td>📊 <strong>Executives & Investors</strong></td><td>Identify risk exposure, reduce liability, validate ethics claims</td></tr>
    <tr><td>⚖️ <strong>Academics & Policy Experts</strong></td><td>Translate evolving laws into enforceable rules</td></tr>
    <tr><td>🌱 <strong>Social & DEIA Advocates</strong></td><td>Protect vulnerable communities from AI harm</td></tr>
    <tr><td>🧠 <strong>Researchers & Audit Partners</strong></td><td>Prototype models with transparent, clause-aware enforcement</td></tr>
  </table>
  <img class="hero-image" src="../assets/stakeholder-value.png" alt="BiasGuard Community Value" />

  <h2>🔌 How It Integrates</h2>
  <p>BiasGuard runs in your CI/CD workflows, supporting AWS Bedrock, SageMaker, Apigee, and more.</p>
  <img class="hero-image" src="../assets/integration_slide.png" alt="Integration Workflow" />

  <h2>🔄 CI/CD Workflow</h2>
  <p>From rule submission to enforcement, BiasGuard ensures transparency and governance from the start.</p>
  <img class="full-width"
